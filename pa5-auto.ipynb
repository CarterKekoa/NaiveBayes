{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA4 Simple Classifiers (Naive Bayes)\n",
    "## Part 2: Auto Dataset Classification  \n",
    "Write a Jupyter Notebook (pa4.ipynb) that uses your mysklearn package to build simple classifiers for the \"pre-processed\" automobile dataset (auto-data-removed-NA.txt) you created for PA2. In the Notebook, describe the steps, log any assumptions and/or issues you had in doing the steps, and provide insights on the step results. All re-usable utility functions should be separate from your Notebook in an appropriate module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myutils as myutils\n",
    "importlib.reload(myutils)\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "source": [
    "### Step 2 Train/Test Sets: Random Instances and kNN  \n",
    "Create a nearest neighbor classifier for mpg that uses the number of cylinders, weight, and acceleration attributes to predict mpg for k = 5. Be sure to normalize the three attribute values and also use the Euclidean distance metric. Similar to Step 1, test your classifier by selecting 5 random instances from the dataset, predict their corresponding mpg ranking, and then show their actual mpg ranking:\n",
    "* Changes:\n",
    "    * A scale function needed to be made to scale the data to be between [0, 1]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================================\nSTEP 2: Naive Bayes 5 random predictions\n========================================\ninstance: [22.0, 6.0, 198.0, 95.0, 2833.0, 15.5, 70.0, 1.0, 'plymouth duster', 2547.0]\nclass: 5 actual: 5\ninstance: [14.0, 8.0, 318.0, 150.0, 4457.0, 13.5, 74.0, 1.0, 'dodge coronet custom (sw)', 3882.0]\nclass: 2 actual: 2\ninstance: [26.0, 4.0, 91.0, 70.0, 1955.0, 20.5, 71.0, 1.0, 'plymouth cricket', 1915.0]\nclass: 7 actual: 6\ninstance: [27.2, 4.0, 141.0, 71.0, 3190.0, 24.8, 79.0, 2.0, 'peugeot 504', 8040.0]\nclass: 5 actual: 7\ninstance: [26.5, 4.0, 140.0, 72.0, 2565.0, 13.6, 76.0, 1.0, 'ford pinto', 3025.0]\nclass: 5 actual: 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "importlib.reload(myutils)\n",
    "\n",
    "# Get the file data\n",
    "fname = os.path.join(\"input_data\", \"auto-data-removed-NA.csv\")\n",
    "auto_data = MyPyTable().load_from_file(fname)\n",
    "auto_data.remove_rows_with_missing_values()\n",
    "\n",
    "# Grab the car cylinders, weight, model year and store in a list\n",
    "cylinders = auto_data.get_column('cylinders')\n",
    "weight = myutils.convert_weight(auto_data.get_column('weight'))\n",
    "model_year = auto_data.get_column('model year')\n",
    "\n",
    "# split the data\n",
    "X_train = [[cylinders[i],weight[i],model_year[i]] for i in range(len(cylinders))]\n",
    "y_train = myutils.convert_rating(auto_data.get_column('mpg'))\n",
    "\n",
    "# Fit to the Naive Bayes Classifier\n",
    "mnbc = MyNaiveBayesClassifier()\n",
    "mnbc.fit(X_train, y_train)\n",
    "\n",
    "# randomize the data for 5 rows\n",
    "rand_rows = myutils.get_rand_rows(auto_data, 5)\n",
    "print(\"========================================\")\n",
    "print(\"STEP 2: Naive Bayes 5 random predictions\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# for row in the random row list\n",
    "X_test = [[row[1],myutils.get_weight(row[4]),row[6]] for row in rand_rows]\n",
    "actual = [myutils.get_rating(row[0]) for row in rand_rows]\n",
    "\n",
    "# predict the values\n",
    "predicted = mnbc.predict(X_test)\n",
    "myutils.prediction_pretty_print(rand_rows,actual,predicted)"
   ]
  },
  {
   "source": [
    "### Step 3 Train/Test Sets: Random Sub-sampling\n",
    "Compute the predictive accuracy and error rate of the two classifiers using random sub-sampling with k = 10. Your output should look something like this (where the ??'s should be replaced by actual values):\n",
    "* This one was a bit difficult but didnt require me to create any new funcitons to pull it off.\n",
    "* Data:\n",
    "    * The accuracy seemed to run a bit low which means that the algorithm was not regularly correct in its predictions. This also means the error rate was high."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================================\nSTEP 3: Naive Bayes predictive accuracy\n========================================\nRandom Subsample (2:1 Train/Test)\nNaive Bayes: accuracy = 0.38372093023255816 error rate =  0.6162790697674418\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(myutils)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"STEP 3: Naive Bayes predictive accuracy\")\n",
    "print(\"========================================\")\n",
    "print('Random Subsample (2:1 Train/Test)')\n",
    "\n",
    "# split the data\n",
    "split_xtrain, split_xtest, split_ytrain, split_ytest = myevaluation.train_test_split(X_train, y_train, shuffle=True)\n",
    "\n",
    "# Fit the data for Naive Bayes\n",
    "mnbc.fit(split_xtrain,split_ytrain)\n",
    "\n",
    "# Predict using Naive Bayes\n",
    "predicted = mnbc.predict(split_xtest)\n",
    "\n",
    "# Print the accuracy data\n",
    "accuracy = myutils.get_accuracy(split_ytest, predicted)\n",
    "print('Naive Bayes: accuracy =', accuracy, 'error rate = ', (1-accuracy))"
   ]
  },
  {
   "source": [
    "### Step 4 Train/Test Sets: Cross Validation\n",
    "Compute the predictive accuracy and error rate of the two classifiers using separate training and test sets. You should use mpg rankings for both k-fold cross validation and stratified k-fold cross validation with k = 10. Your output should look something like this (where the ??'s should be replaced by actual values):\n",
    "* Corrections:\n",
    "    * I needed to make a function that counted the predictions that were correct. \n",
    "* Data:\n",
    "    * The predictions for the cross validation were actually pretty high menaing it was able to predict rather well.\n",
    "    * However the stratified k fold was not regularly very accurate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================================\nSTEP 4: Naive Bayes Predictive Accuracy\n===========================================\n10-Fold Cross Validation\nNaive Bayes: accuracy = 0.5366795366795367 error rate =  0.4633204633204633\n\nStratified 10-Fold Cross Validation\nNaive Bayes: accuracy = 0.5366795366795367 error rate =  0.4633204633204633\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"STEP 4: Naive Bayes Predictive Accuracy\")\n",
    "print(\"===========================================\")\n",
    "print(\"10-Fold Cross Validation\")\n",
    "\n",
    "# fold the column data\n",
    "train_folds, test_folds = myevaluation.kfold_cross_validation(X_train, 10)\n",
    "fold_xtrain, fold_ytrain, fold_xtest, fold_ytest = myutils.get_from_folds(X_train, y_train, train_folds, test_folds)\n",
    "\n",
    "# Fit the data using Naive Bayes\n",
    "mnbc.fit(fold_xtrain, fold_ytrain)\n",
    "\n",
    "# Predict the data using Naive Bayes\n",
    "predicted = mnbc.predict(fold_xtest)\n",
    "accuracy = myutils.get_accuracy(fold_ytest, predicted)\n",
    "print('Naive Bayes: accuracy =', accuracy, 'error rate = ', (1-accuracy))\n",
    "\n",
    "print()\n",
    "print(\"Stratified 10-Fold Cross Validation\")\n",
    "\n",
    "# Make the folds\n",
    "strattrain_folds, strattest_folds = myevaluation.stratified_kfold_cross_validation(X_train, y_train, 10)\n",
    "\n",
    "# get the train and test lists\n",
    "strat_xtrain, strat_ytrain, strat_xtest, strat_ytest = myutils.get_from_folds(X_train, y_train, train_folds, test_folds)\n",
    "\n",
    "# Fit the data using Naive Bayes\n",
    "mnbc.fit(strat_xtrain, strat_ytrain)\n",
    "\n",
    "# Predict the data using Naive Bayes\n",
    "predicted = mnbc.predict(strat_xtest)\n",
    "accuracy = myutils.get_accuracy(strat_ytest, predicted)\n",
    "print('Naive Bayes: accuracy =', accuracy, 'error rate = ', (1-accuracy))"
   ]
  },
  {
   "source": [
    "### Step 5 Confusion Matrices  \n",
    "Create confusion matrices for each classifier based on the stratified 10-fold cross validation results. You can use the tabulate package to display your confusion matrices (it is also okay to format the table manually). Here is an example:\n",
    "* Data:\n",
    "    * It seems the matrix was not able to guess the correct label very often."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n===========================================\nSTEP 5: Confusion Matrices\n===========================================\n\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n    1   26    1    1    0    0    0    0    0    0     0       29              89.66\n    2    8    6    2    0    0    0    0    0    0     0       18              33.33\n    3    8    6   13    9    0    0    0    0    0     0       39              33.33\n    4    2    1   10   31    5    2    0    0    0     0       55              56.36\n    5    0    0    2   16   20    9    0    0    0     0       52              38.46\n    6    0    0    0    1    6   22    4    1    0     0       40              55\n    7    0    0    0    0    4    9   11    3    0     0       34              32.35\n    8    0    0    0    0    1    1    6   10    0     0       26              38.46\n    9    0    0    0    0    0    0    1    1    0     0       11               0\n   10    0    0    0    0    0    0    0    0    0     0       10               0\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(myutils)\n",
    "\n",
    "print(\"===========================================\")\n",
    "print(\"STEP 5: Confusion Matrices\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# create the confusion matrix\n",
    "matrix = myevaluation.confusion_matrix(strat_ytest, predicted, [0,1,2,3,4,5,6,7,8,9,10])\n",
    "table_header = ['MPG', 1,2, 3 ,4, 5, 6, 7, 8, 9, 10, 'Total', 'Recognition (%)']\n",
    "\n",
    "# Prepare the table to be printed\n",
    "myutils.add_conf_stats(matrix)\n",
    "myutils.print_tabulate(matrix, table_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}