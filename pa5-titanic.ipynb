{
 "cells": [
  {
   "source": [
    "# Part 3: Titanic Classification  \n",
    "\n",
    "The titanic dataset (included in the input_data directory) consists of instances representing passengers aboard the Titanic ship that sank in the North Atlantic Ocean on 15 April 1912. The dataset has three attributes describing a passenger (class, age, sex) and a class label (survived) denoting whether the passenger survived the shipwreck or not.\n",
    "\n",
    "Write a Jupyter Notebook (pa5-titanic.ipynb) that uses your mysklearn package to build Naive Bayes and $k$-nearest neighbor classifiers to predict survival from the titanic dataset (titanic.txt). Your classifiers should use class, age, and sex attributes to determine the survival value. Note that since that class, age, and sex are categorical attributes, you will need to update your kNN implementation to properly compute the distance between categorical attributes. See the B Nearest Neighbors Classification notes on Github for how to go about doing this.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myutils as myutils\n",
    "importlib.reload(myutils)\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier, MyZeroRClassifier, MyRandomClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "source": [
    "Evaluate the performance of your classifiers using stratified k-fold cross validation (with k = 10) and generate confusion matrices for the two classifiers. As in PA4, report both accuracy and error rate for the two approaches.\n",
    "\n",
    "### Naive Bayes Classifier (Confusion Matrices)\n",
    "* The first step is of course to grab and process the data. This involves grabbing the columns we want to work with. This data is then split up and preped to be trained. These are fit to the Classifier and places into folds using kfold cross validation. This data is used to make a prediction which is placed into a confusion matrix.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================================\nNaive Bayes Confusion Matrix\n===========================================\n==========  =====  ====  =======  =================\nSurvived      yes    no    Total    Recognition (%)\n==========  =====  ====  =======  =================\n1            1364   126     1490              91.54\n2             362   349      711              49.09\nTotal        1726   475     2201              77.83\n==========  =====  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "importlib.reload(myutils)\n",
    "\n",
    "# Get the file data\n",
    "fname = os.path.join(\"input_data\", \"titanic.txt\")\n",
    "titanic_data = MyPyTable().load_from_file(fname)\n",
    "titanic_data.remove_rows_with_missing_values() # prep the data by removing any missing values\n",
    "\n",
    "# Grab the class, age, sex and store in a list\n",
    "titatic_class = titanic_data.get_column('class')\n",
    "titatic_age = titanic_data.get_column('age')\n",
    "titatic_sex = titanic_data.get_column('sex')\n",
    "\n",
    "# split the data\n",
    "X_train = [[titatic_class[i],titatic_age[i],titatic_sex[i]] for i in range(len(titatic_class))]\n",
    "y_train = titanic_data.get_column('survived')\n",
    "\n",
    "# Fit to the Naive Bayes Classifier\n",
    "mnbc = MyNaiveBayesClassifier()\n",
    "mnbc.fit(X_train, y_train) # fit the data using Naive Bayes\n",
    "\n",
    "# fold the column data\n",
    "strattrain_folds, strattest_folds = myevaluation.stratified_kfold_cross_validation(X_train, y_train, 10)\n",
    "X_train_strat, y_train_strat, X_test_strat, y_test_strat = myutils.get_from_folds(X_train, y_train, strattrain_folds, strattest_folds)\n",
    "\n",
    "# make a prediction using Naive Bayes\n",
    "predicted_bayes = mnbc.predict(X_test_strat)\n",
    "\n",
    "print(\"===========================================\")\n",
    "print(\"Naive Bayes Confusion Matrix\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# create the confusion matrix\n",
    "matrix = myevaluation.confusion_matrix(y_test_strat, predicted_bayes, ['yes','no'])\n",
    "\n",
    "# print the data\n",
    "table_header = ['Survived', 'yes', 'no', 'Total', 'Recognition (%)']\n",
    "myutils.titanic_stats(matrix)\n",
    "myutils.print_tabulate(matrix, table_header)"
   ]
  },
  {
   "source": [
    "### Knn Classifier (Confusion Matrix)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bda5582ad530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# make a prediction using Knn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmknc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_strat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pa5-CarterKekoa/mysklearn/myclassifiers.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[1;32m    173\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pa5-CarterKekoa/mysklearn/myclassifiers.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# scale the list and test list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mscaled_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mall_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pa5-CarterKekoa/mysklearn/myutils.py\u001b[0m in \u001b[0;36mscale\u001b[0;34m(vals, test_vals)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"row[i]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"   mins_list[i]:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"     maxs_list[i]:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmins_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmins_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mscaled_vals_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# Fit to the Naive Bayes Classifier\n",
    "mknc = MyKNeighborsClassifier(10)\n",
    "mknc.fit(X_train, y_train) # fit the data using Knn\n",
    "\n",
    "# fold the column data\n",
    "strattrain_folds, strattest_folds = myevaluation.stratified_kfold_cross_validation(X_train, y_train, 10)\n",
    "X_train_strat, y_train_strat, X_test_strat, y_test_strat = myutils.get_from_folds(X_train, y_train, strattrain_folds, strattest_folds)\n",
    "\n",
    "# make a prediction using Knn\n",
    "predicted = mknc.predict(X_test_strat)\n",
    "print(predicted)\n",
    "\n",
    "print(\"===========================================\")\n",
    "print(\"Knn Confusion Matrix\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# create the confusion matrix\n",
    "matrix = myevaluation.confusion_matrix(y_test_strat, predicted, ['yes','no'])\n",
    "\n",
    "# print the data\n",
    "table_header = ['Survived', 'yes', 'no', 'Total', 'Recognition (%)']\n",
    "myutils.titanic_stats(matrix)\n",
    "myutils.print_tabulate(matrix, table_header)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Zero R Classifier (Confusion Matrix)\n",
    "* Fit the data to Zero R Classifier and set the predictions. Put these predictions in a Confusion Matrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================================\nMyZeroRClassifier Confusion Matrix\n===========================================\n==========  =====  ====  =======  =================\nSurvived      yes    no    Total    Recognition (%)\n==========  =====  ====  =======  =================\n1            1490     0     1490              100\n2             711     0      711                0\nTotal        2201     0     2201               67.7\n==========  =====  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"MyZeroRClassifier Confusion Matrix\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "mzrc = MyZeroRClassifier()\n",
    "mzrc.fit(X_train_strat, y_train_strat)\n",
    "\n",
    "predicted_zero = mzrc.predict(X_test_strat)\n",
    "\n",
    "matrix = myevaluation.confusion_matrix(y_test_strat, predicted_zero, ['yes','no'])\n",
    "table_header = ['Survived', 'yes', 'no', 'Total', 'Recognition (%)']\n",
    "myutils.titanic_stats(matrix)\n",
    "myutils.print_tabulate(matrix, table_header)"
   ]
  },
  {
   "source": [
    "### Random Classifier (Confusion Matrix)\n",
    "* Fit the data to Random Classifier and set the predictions. Put these predictions in a Confusion Matrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================================\nMyRandomClassifier Confusion Matrix\n===========================================\n==========  =====  ====  =======  =================\nSurvived      yes    no    Total    Recognition (%)\n==========  =====  ====  =======  =================\n1            1017   473     1490              68.26\n2             481   230      711              32.35\nTotal        1498   703     2201              56.66\n==========  =====  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"MyRandomClassifier Confusion Matrix\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "mrc = MyRandomClassifier()\n",
    "mrc.fit(X_train_strat, y_train_strat)\n",
    "\n",
    "predicted_zero = mrc.predict(X_test_strat)\n",
    "\n",
    "matrix = myevaluation.confusion_matrix(y_test_strat, predicted_zero, ['yes','no'])\n",
    "table_header = ['Survived', 'yes', 'no', 'Total', 'Recognition (%)']\n",
    "myutils.titanic_stats(matrix)\n",
    "myutils.print_tabulate(matrix, table_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}